name: js unit test gen
on: # yamllint disable-line rule:truthy
  workflow_call:
    inputs:
      dryrun:
        description: 'running mode'
        required: true
        default: true
        type: boolean
      build_image:
        description: 'build image or not'
        required: true
        default: false
        type: boolean

jobs:
  test-js-unittest:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout action repo for latest image
        if: ${{ inputs.build_image == true }}
        id: checkout
        uses: actions/checkout@v4
      - name: Set up Docker Buildx
        if: ${{ inputs.build_image == true }}
        uses: docker/setup-buildx-action@v3
      - name: run local dev script
        if: ${{ inputs.build_image == true }}
        id: local-image-build
        run: |
          docker build -t ghcr.io/samyuan1990/openai_codeagent-action:latest .
      - name: Checkout
        id: checkout_target
        uses: actions/checkout@v4
      - name: Setup Node.js
        id: setup-node
        uses: actions/setup-node@v4
        with:
          node-version-file: .node-version
          cache: npm
      - name: Install Dependencies
        id: npm-ci
        run: npm install && npx jest --coverage && cp -r coverage src
      - name: Test Local Action
        id: Lint_with_LLM
        uses: ./
        with:
          baseURL: https://api.deepseek.com
          apiKey: dummy
          model: deepseek-chat
          dirpath: '/workdir/src'
          maxIterations: 1
          dryRun: true
          runType: jsunittest
      - name: output check
        shell: bash
        run: |
          echo '${{ steps.Lint_with_LLM.outputs.LLMresponse }}'
          echo '${{ steps.Lint_with_LLM.outputs.final_prompt }}'
          echo '${{ steps.Lint_with_LLM.outputs.avg_prompt_precent }}'
          echo '${{ steps.Lint_with_LLM.outputs.avg_content_precent }}'
      - name: Create new issue
        uses: imjohnbo/issue-bot@v3
        if: ${{ inputs.dryrun == false }}
        with:
          title: CVE cross check with deployment
          body: |-
            :wave: Hi maintainers, here is LLM's deployment suggested according to your CVSS scan result.
            ${{ steps.Lint_with_LLM.outputs.LLMresponse }}
