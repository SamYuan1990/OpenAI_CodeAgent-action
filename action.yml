name: 'OpenAI_CodeAgent-action'
description: 'Smart lint with LLM'
author: 'SamYuan1990'

# Define your inputs here.
inputs:
  # running control
  dryRun:
    description: dryRun option
  maxIterations:
    description:
      'an optional setting for the maximum number of iterations we invokes
      openAI endpoint'
  # model option
  baseURL:
    description: 'url for your openAI API endpoint'
  apiKey:
    description: 'apikey for your openAI API endpoint'
  model:
    description: 'the model we are going to interact with openAI API endpoint'
  prompt:
    description:
      'the prompt string your are going to talk with openAI API endpoint'
  # feature selection
  runType:
    description: 'action type, jsunittest or godoc'
  dirPath:
    description: 'the dir path of your source code'
  # feature specific
  deploymentfile:
    description: 'the deployment yaml if you use CVE2Deployment'

outputs:
  LLMresponse:
    description: 'LLM response if just single job'
    value: ${{ steps.LLMresponse.outputs.LLMresponse }}
  final_prompt:
    description: 'final_prompt if just single job'
    value: ${{ steps.LLMresponse.outputs.final_prompt }}
  avg_content_precent:
    description: 'avg_content_precent'
    value: ${{ steps.LLMresponse.outputs.avg_content_precent }}
  avg_prompt_precent:
    description: 'avg_prompt_precent'
    value: ${{ steps.LLMresponse.outputs.avg_prompt_precent }}

runs:
  using: 'composite'
  steps:
    - name: Set up Docker as container env
      uses: docker/setup-buildx-action@v3

    - name: run local dev script
      shell: bash
      id: local-dev
      run: |
        docker run -e baseURL=${{ inputs.baseURL }} \
         -e apiKey=${{ inputs.apiKey }} \
         -e model=${{ inputs.model }} \
         -e dirPath=${{ inputs.dirPath }} \
         -e dryRun=${{ inputs.dryRun }} \
         -e runType=${{ inputs.runType }} \
         -e maxIterations=${{ inputs.maxIterations }} \
         -e deploymentfile=${{ inputs.deploymentfile }} \
         -e prompt=${{ inputs.prompt }} \
         -v "$(pwd)":/workdir \
         ghcr.io/samyuan1990/openai_codeagent-action:latest
    - id: LLMresponse
      shell: bash
      run: |
        VALUE=$(jq -r --fail-with-exit LLMresponse <<< "$(cat $(pwd)/GenAI_output/summary.json)")
        echo "LLMresponse=$(VALUE)" >> $GITHUB_OUTPUT
        VALUE=$(jq -r --fail-with-exit final_prompt <<< "$(cat $(pwd)/GenAI_output/summary.json)")
        echo "final_prompt=$(VALUE)" >> $GITHUB_OUTPUT
        VALUE=$(jq -r --fail-with-exit avg_prompt_precent <<< "$(cat $(pwd)/GenAI_output/summary.json)")
        echo "avg_prompt_precent=$(VALUE)" >> $GITHUB_OUTPUT
        VALUE=$(jq -r --fail-with-exit avg_content_precent <<< "$(cat $(pwd)/GenAI_output/summary.json)")
        echo "avg_content_precent=$(VALUE)" >> $GITHUB_OUTPUT
